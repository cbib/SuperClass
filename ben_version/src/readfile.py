#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""Try to read the files generated byt the bic.

XXX Add more explanations.
"""

# imports
import os
import re
import glob
from collections import OrderedDict
import logging
logging.basicConfig(level=logging.INFO)

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import constants
pd.options.mode.chained_assignment = None
from pandas.tools.plotting import scatter_matrix, andrews_curves
from astropy.visualization import hist
from joblib import Memory, Parallel, delayed
from array import array

from outliers import smirnov_grubbs as grubbs

from constants import *
#Cache folder

# if not os.path.exists(CACHE_DIR):
#     logging.error('Cache directory [%s] does not exists!\n Use /tmp insted' % CACHE_DIR)
#     CACHE_DIR = '/tmp'

# memory = Memory(cachedir=CACHE_DIR, verbose=True)

def extract_slot_features(folder, expname):
	"""Extract the features from the files of the folder.
	At the moment, only read the diffusion coefficient and build an histogram.

	TODO Add additional calls to read additional features

	folder:
		Folder which contains the data
	expname:
		Experiment name (used to select which files to read)
	"""

	logging.info("Treat exp '" + expname + "' from " + folder)
	assert (folder.find(expname.replace("_MIA",".MIA")) != -1)



	coeff_fname = os.path.join(folder, expname + "-AllROI-D.txt")
	coeff_feat = extract_diffusion_coefficient_features(coeff_fname)

	msd_fname = coeff_fname
	msd_feat = extract_msd_features(msd_fname)


	traj_fname = os.path.join(folder, expname + ".trc")
	traj_feat = extract_trajectory_features(traj_fname)

	# merge features
	all_feat = pd.concat([coeff_feat, traj_feat, msd_feat], axis=1)
	all_feat.index = [folder]

	return all_feat



# @memory.cache
def extract_trajectory_features(traj_fname):
	"""Read the trajectory file and extract its histogram
	
	traj_fname: 
		File containing the trajectories

	Returns the trajectory features (i.e. histogram)
	"""

	assert (os.path.exists(traj_fname))

	data = pd.io.parsers.read_csv(traj_fname,
								names = ['TRAJ_ID', 'FRAME_NB', 'X', 'Y', 'MOLECULE_SIZE', 'INTENSITY'],
								sep=None,
								skipinitialspace=True,
								index_col=False)

	# Get the number of frames per trajectory
	nb_frames = np.array(
		[group.count().values[0] for _id, group in data[['TRAJ_ID', 'FRAME_NB']].groupby('TRAJ_ID')]
	)

	# Cut extremums
	nb_frames[nb_frames<TRAJECTORY_FRAMES_MIN] = TRAJECTORY_FRAMES_MIN
	nb_frames[nb_frames>TRAJECTORY_FRAMES_MAX] = TRAJECTORY_FRAMES_MAX

	# Compute a normalized histogram
	hist, bins = np.histogram(nb_frames, bins=TRAJECTORY_FRAMES_HISTOGRAM_BINS)
	hist = hist / float(hist.sum())

	# Build the features
	feat = OrderedDict( zip(TRAJECTORY_FRAMES_HISTOGRAM_LABELS, hist))
	#df = pd.DataFrame([feat], index=[traj_fname])
	df = pd.DataFrame([feat])
	df = df.reindex_axis(feat.keys(), axis=1) #order seems eroneous

	return df


def extract_msd_features(msd_fname):
	"""Read Mean Square Distance features.

	msd_name: 
		file which contains the MSD (in fact the same than the diffusion coefficient)
	"""

	assert(os.path.exists(msd_fname))

	# configuration of pandas to read the file properly
	data = pd.io.parsers.read_csv(
				msd_fname,
				sep="\t",
				skipinitialspace=True,
				header=None,
				names = [ROI_COL, TRACE_COL, DENSITY_COL, MSD_COL, MSE_COL],
				skiprows=3,
				index_col=False,
				encoding='latin1')
				

	# Verify that the file read respect the structure of the files used during the development
	# of the library
	assert len(data[ROI_COL].unique()) == 1, "Currently implemented if there is one ROI"
	assert (data[TRACE_COL].unique().shape[0] == data[TRACE_COL].count()) , "Only one density per Trace"

	# Get the density values and fix the extremums
	msd = data[MSD_COL].values

	return generate_MSD_feature_vector(msd)



def plotHistogram(data):

	histFrdDiac, binsFrdDiac = np.histogram(data, bins='fd')
	print histFrdDiac
	print binsFrdDiac
	histFrdDiac = histFrdDiac/float(histFrdDiac.sum())
	plt.hist(histFrdDiac, binsFrdDiac, normed=1, facecolor='g', alpha=0.75)

	plt.show()



def plotHistogram2(df):
	plt.figure(1)
	temp = 211
	for ROI, data in df.groupby('ImageNumber'):
		plt.subplot(temp)
		histFrdDiac, binsFrdDiac = np.histogram(data['MSD_0'], bins='fd')
		histFrdDiac = histFrdDiac/float(histFrdDiac.sum())
		plt.hist(histFrdDiac, binsFrdDiac, normed=True, facecolor='m', alpha=0.75)
		plt.xlabel( 'Bins' )
		plt.ylabel( 'MSD sum' )
		plt.show()
		temp=temp+1

def generate_feature_vector(data,min,max,hist_bins,hist_labels):
    """Generate the MSD feature vector from the MSD data"""

    data[data<min] = min
    data[data>max] = max
    #print "MSD : "
    #print msd
    #print("MSD_MIN : ", MSD_MIN, "; MSD_MAX : ",MSD_MAX)
    #print("????? : ",  msd[msd>MSD_MAX])

    # Compute a normalized histogram
    hist, bins = np.histogram(data,bins=hist_bins)
    #plt.hist(hist, bins=bins, facecolor='m', alpha=0.75)
    #plt.show()
    
    hist = hist/float(hist.sum())
    
    #MSD_HISTOGRAM_LABELS =bins
    #plt.hist(hist, bins=bins, facecolor='m', alpha=0.75)
    #plt.show()
    # Build the features
    feat = OrderedDict( zip(hist_labels, hist))
    df = pd.DataFrame([feat])
    #df = pd.DataFrame([feat], index=[coeff_fname])
    df = df.reindex_axis(feat.keys(), axis=1) #order seems eroneous
    #print "df:"
    #print df

    return df
    
    

def generate_msd_feature_vector(msd,MSD_MIN,MSD_MAX,MSD_HISTOGRAM_BINS,MSD_HISTOGRAM_LABELS):
	"""Generate the MSD feature vector from the MSD data"""


	msd[msd<MSD_MIN] = MSD_MIN
	msd[msd>MSD_MAX] = MSD_MAX
	#print "MSD : "
	#print msd
	#print("MSD_MIN : ", MSD_MIN, "; MSD_MAX : ",MSD_MAX)
	#print("????? : ",  msd[msd>MSD_MAX])

	# Compute a normalized histogram
	hist, bins = np.histogram(msd, 
					   bins=MSD_HISTOGRAM_BINS)
	hist = hist/float(hist.sum())
	#MSD_HISTOGRAM_LABELS =bins
	#plt.hist(hist, bins=bins, facecolor='m', alpha=0.75)

	# Build the features
	feat = OrderedDict( zip(MSD_HISTOGRAM_LABELS, hist))
	df = pd.DataFrame([feat])
	#df = pd.DataFrame([feat], index=[coeff_fname])
	df = df.reindex_axis(feat.keys(), axis=1) #order seems eroneous
        #print "df:"
        #print df

	return df

def generate_mse_feature_vector(mse):
	"""Generate the MSD feature vector from the MSD data"""

	mse[mse<MSD_MIN] = MSD_MIN
	mse[mse>MSD_MAX] = MSD_MAX

	# Compute a normalized histogram
	hist, bins = np.histogram(mse, 
					   bins=MSD_HISTOGRAM_BINS)
	hist = hist/float(hist.sum())

	# Build the features
	feat = OrderedDict( zip(MSD_HISTOGRAM_LABELS, hist))
	df = pd.DataFrame([feat])
	df = df.reindex_axis(feat.keys(), axis=1) #order seems eroneous

	return df



# @memory.cache
def extract_diffusion_coefficient_features(coeff_fname):
	"""Read the diffusion coefficient and build the appropriate histogram.

	coeff_name:
		File containing the coefficient of each path
	"""

	assert(os.path.exists(coeff_fname))

	# configuration of pandas to read the file properly
	data = pd.io.parsers.read_csv(
				coeff_fname,
				sep="\t",
				skipinitialspace=True,
				header=None,
				names = [ROI_COL, TRACE_COL, DENSITY_COL, MSD_COL, MSE_COL],
				skiprows=3,
				index_col=False,
				encoding='latin1')
				

 
	# Verify that the file read respect the structure of the files used during the development
	# of the library
	assert len(data[ROI_COL].unique()) == 1, "Currently implemented if there is one ROI"
	assert (data[TRACE_COL].unique().shape[0] == data[TRACE_COL].count()) , "Only one density per Trace"

	
	# Get the density values and fix the extremums
	density = data[DENSITY_COL].values
	return generate_diffusion_coefficient_features_vector(data[ROI_COL],density)


def _extract_experiment_features_inner_loop(expdir):
		logging.info("Treat the folder " + expdir)
		expname = os.path.basename(expdir).replace('.MIA', '_MIA')
		expdir = os.path.join(expdir, 'tracking')
		assert os.path.exists(expdir)

		return extract_slot_features(expdir, expname)


def extract_experiment_features(experiment_dir):
	"""Extract the features of each slot of the experiment.
	The method has been developped with a data folder containing several MIA folders.
	It seems it is not the case with the new datasets.
	"""

	logging.info("Get feature samples for experiment in " + experiment_dir)

	# BUG never parallel here ...
	samples = Parallel(n_jobs=1, verbose=10)(
		delayed(_extract_experiment_features_inner_loop)(expdir)
			for expdir in glob.glob(os.path.join(experiment_dir, '*.MIA'))
	)

	return pd.concat(samples)


# ===== Reading routines specific for Anne's work =====
#def extract_features_of_this_ROI(df, index):
#	"""Extract the features for this specific ROI.
    #XXX several steps are copy/pasted from readfile.py
	#"""
# 
#	# XXX WARNING it seams that min/max values previously 
#	#	 set are not compatible with that
#	msd_features = generate_MSD_feature_vector(df['MSD_0'])
#	diffusion_features = generate_diffusion_coefficient_features_vector(df['Diffusion_Coefficient'])
#	# XXX ERROR we are unable to generate the tracking stuff
#
#	# XXX Merge the set of features
#	all_feat = pd.concat([diffusion_features, msd_features], 
#						 axis=1,
#						 verify_integrity=False)
#
#	all_feat['index'] = index
#	all_feat = all_feat.set_index('index')
#	#print all_feat
#	return all_feat
def freedman_bin_width(data, return_bins=False):
    """Return the optimal histogram bin width using the Freedman-Diaconis rule

    The Freedman-Diaconis rule is a normal reference rule like Scott's
    rule, but uses rank-based statistics for results which are more robust
    to deviations from a normal distribution.

    Parameters
    ----------
    data : array-like, ndim=1
        observed (one-dimensional) data
    return_bins : bool (optional)
        if True, then return the bin edges

    Returns
    -------
    width : float
        optimal bin width using the Freedman-Diaconis rule
    bins : ndarray
        bin edges: returned if ``return_bins`` is True

    Notes
    -----
    The optimal bin width is

    .. math::
        \Delta_b = \frac{2(q_{75} - q_{25})}{n^{1/3}}

    where :math:`q_{N}` is the :math:`N` percent quartile of the data, and
    :math:`n` is the number of data points [1]_.

    References
    ----------
    .. [1] D. Freedman & P. Diaconis (1981)
       "On the histogram as a density estimator: L2 theory".
       Probability Theory and Related Fields 57 (4): 453-476

    See Also
    --------
    knuth_bin_width
    scott_bin_width
    bayesian_blocks
    histogram
    """
    data = np.asarray(data)
    if data.ndim != 1:
        raise ValueError("data should be one-dimensional")

    n = data.size
    if n < 4:
        raise ValueError("data should have more than three entries")

    v25, v75 = np.percentile(data, [25, 75])
    dx = 2 * (v75 - v25) / (n ** (1 / 3))

    if return_bins:
        dmin, dmax = data.min(), data.max()
        Nbins = max(1, np.ceil((dmax - dmin) / dx))
        bins = dmin + dx * np.arange(Nbins + 1)
        return dx, bins
    else:
        return dx
 
 

    

def freedman_diaconis(object_df,point_df):
    """Return the optimal histogram bin width using the Freedman-Diaconis rule"""
    da_global,bins_global = freedman_bin_width(point_df['Dinst'], True)
    print 'best bin width for Dinst data found with Freedman-Diaconis '
    print da_global
    print 'resulting following interval for histogram: '
    print bins_global 

    DINST_MIN=bins_global[0]
    DINST_MAX=bins_global[len(bins_global)-1]
    DINST_HISTOGRAM_BINS=bins_global
    DINST_HISTOGRAM_LABELS = ["HIST_DINST_%f" % _ for _ in DINST_HISTOGRAM_BINS[:-1]]

    da_global,bins_global = freedman_bin_width(object_df['MSD_0'], True)
    print 'best bin width for MSD data found by Freedman-Diaconis:' 
    print da_global
    print 'resulting following interval for histogram: '
    print bins_global  
    #ideal_MSD_binwidth=da_global
    MSD_MIN=bins_global[0]
    MSD_MAX=bins_global[len(bins_global)-1]
    MSD_HISTOGRAM_BINS=bins_global
    MSD_HISTOGRAM_LABELS = ["HIST_MSD_%f" % _ for _ in MSD_HISTOGRAM_BINS[:-1]]
    
    da_global, bins_global = freedman_bin_width(object_df['Diffusion_Coefficient'], True)
    print 'best bin width for Diffusion coefficient found by Freedman-Diaconis '
    print da_global
    print 'resulting following interval for histogram: '
    print bins_global 
    DENSITY_MIN=bins_global[0]
    DENSITY_MAX=bins_global[len(bins_global)-1]
    DENSITY_HISTOGRAM_BINS=bins_global
    DENSITY_HISTOGRAM_LABELS = ["DENSITY_MSD_%f" % _ for _ in DENSITY_HISTOGRAM_BINS[:-1]]
    
    return (DENSITY_MIN,DENSITY_MAX,DENSITY_HISTOGRAM_BINS,DENSITY_HISTOGRAM_LABELS,MSD_MIN,MSD_MAX,MSD_HISTOGRAM_BINS,MSD_HISTOGRAM_LABELS,DINST_MIN,DINST_MAX,DINST_HISTOGRAM_BINS,DINST_HISTOGRAM_LABELS) 
    
def plot_freedman(df,ROI):
    fig, ax = plt.subplots(1, 2, figsize=(10, 4))
    fig.subplots_adjust(left=0.1, right=0.95, bottom=0.15)
    #for i, bins in enumerate(['scott', 'freedman']):
    for i,feature in enumerate(['MSD_0', 'Diffusion_Coefficient']):

            hist(df[feature], bins='freedman', ax=ax[i], histtype='stepfilled',alpha=0.2, normed=True)
            ax[i].set_xlabel('t')
            ax[i].set_ylabel('P(t)')
            #ax[i].set_title('hist(t, bins="{0}")'.format(bins),
            ax[i].set_title('hist(t, bins="freedman for {0}")'.format(feature),
                            fontdict=dict(family='monospace'))
    #filename='histofd'+str(ROI)+'.pdf'
    #fig.savefig('/Users/benjamindartigues/super_class_test/src/'+filename,dpi=fig.dpi)
def generate_diffusion_coefficient_features_vector(density,DENSITY_MIN,DENSITY_MAX,DENSITY_HISTOGRAM_BINS,DENSITY_HISTOGRAM_LABELS):

    density.loc[density<DENSITY_MIN] = DENSITY_MIN
    density.loc[density>DENSITY_MAX] = DENSITY_MAX

    # Compute a normalized histogram
    hist, bins = np.histogram(density, 
                                       bins=DENSITY_HISTOGRAM_BINS)
    hist = hist/float(hist.sum())

    # Build the features
    feat = OrderedDict( zip(DENSITY_HISTOGRAM_LABELS, hist))
    df = pd.DataFrame([feat])
    df = df.reindex_axis(feat.keys(), axis=1) #order seems eroneous

    return df

def generate_dinst_feature_vector(dinst,DINST_MIN,DINST_MAX,DINST_HISTOGRAM_BINS,DINST_HISTOGRAM_LABELS):
    #print DINST_HISTOGRAM_BINS
    dinst.loc[dinst<DINST_MIN] = DINST_MIN
    dinst.loc[dinst>DINST_MAX] = DINST_MAX
    #print DINST_HISTOGRAM_BINS

    # Compute a normalized histogram
    hist, bins = np.histogram(dinst, bins=DINST_HISTOGRAM_BINS)
    hist = hist/float(hist.sum())

    # Build the features
    feat = OrderedDict( zip(DINST_HISTOGRAM_LABELS, hist))
    df = pd.DataFrame([feat])
    df = df.reindex_axis(feat.keys(), axis=1) #order seems eroneous

    return df
 
                   
def extract_wave_tracer_features(df): 

    df_columns = ['ImageNumber', 'total_movement']
    dataTab_noOutliers = pd.DataFrame()
    data_df = pd.DataFrame()
    global_df = pd.DataFrame()
    samples = vec = dfRes= []
    total_length=0

    # print "SIZE BEFORE GRUBBS : " + str(len(df.index))
    # print "MAX TRAJECTORY SIZE (bfg): "+str(df['total_movement'].max())

    if BINNING_TYPE=="freedman_std":
        for ROI,data in df.groupby('ImageNumber'):
            dataTab = []
            for ROI2,data2 in data.groupby('WaveTracerID'):
                dataTab.append(len(data2['WaveTracerID']))
            print ROI
            # data4grubbs = np.array(dataTab)
            data4grubbs = pd.Series(dataTab)
            total_length+=len(data4grubbs.index)

            grubbsResult=grubbs.test(data4grubbs, alpha=0.05)
            # grubbsResult = data4grubbs[data4grubbs < data4grubbs.quantile(.95)]
            # grubbsResult = data4grubbs

            vec = len(grubbsResult)*[ROI]
            dataTab_noOutliers = pd.DataFrame({'ImageNumber' : vec, 'total_movement' : grubbsResult.tolist()})
            data_df= data_df.append(dataTab_noOutliers, ignore_index=True)


        # print data_df
        # globalScores = data_df[data_df['total_movement']< data_df['total_movement'].quantile(.95) ]
        # print globalScores

        # data_df.to_csv(os.path.join(OUTPUT_DIR, "dinstDistribution.csv"),sep=",")
        print "SIZE BEFORE GRUBBS : " + str(total_length)
        print "SIZE AFTER GRUBBS : "+str(len(data_df.index))
        print "TRAJECTORY REMOVED : "+str(total_length-len(data_df.index))
        print "TRAJECTORY Keeped : "+str((len(data_df.index)*100)/total_length)+"%"
        # print "MAX TRAJECTORY SIZE (afg): "+str(data_df['total_movement'].max())
        data_df['total_movement'].plot(kind='line')

        da_global,bins_global = freedman_bin_width(data_df['total_movement'], True)
        DINST_MIN=bins_global[0]
        DINST_MAX=bins_global[len(bins_global)-1]
        DINST_HISTOGRAM_BINS=bins_global
        DINST_HISTOGRAM_LABELS = ["HIST_DINST_%f" % _ for _ in DINST_HISTOGRAM_BINS[:-1]]
        print DINST_HISTOGRAM_LABELS


        for ROI, data in data_df.groupby('ImageNumber'):
            dinst_features = generate_feature_vector(data['total_movement'],DINST_MIN,DINST_MAX,DINST_HISTOGRAM_BINS,DINST_HISTOGRAM_LABELS)
            dinst_features['index'] = ROI
            dinst_features = dinst_features.set_index('index')
            samples.append(dinst_features)


        # print samples
        pd.concat(samples).to_csv(os.path.join(OUTPUT_DIR, "samplesWaveTracer.csv"),sep=",")
    return (pd.concat(samples),DINST_HISTOGRAM_LABELS)


def extract_dinst_features(df):
    samples = []
    DINST_MIN=10e-5
    DINST_MAX=2.5
    DINST_HISTOGRAM_BINS=np.linspace(DINST_MIN, DINST_MAX, num=20)
    DINST_HISTOGRAM_LABELS=["HIST_DINST_%f" % _ for _ in DINST_HISTOGRAM_BINS[:-1]]

    
    if BINNING_TYPE=="freedman_std":  

        da_global,bins_global = freedman_bin_width(df['Dinst_std'], True)

        DINST_MIN=bins_global[0]
        DINST_MAX=bins_global[len(bins_global)-1]
        DINST_HISTOGRAM_BINS=bins_global
        DINST_HISTOGRAM_LABELS = ["HIST_DINST_%f" % _ for _ in DINST_HISTOGRAM_BINS[:-1]]
        for ROI, data in df.groupby('ImageNumber'):
            #print data['Dinst_std']
            dinst_features = generate_dinst_feature_vector(data['Dinst_std'],DINST_MIN,DINST_MAX,DINST_HISTOGRAM_BINS,DINST_HISTOGRAM_LABELS)
            dinst_features['index'] = ROI
            dinst_features = dinst_features.set_index('index')
            samples.append(dinst_features)
    
            
        
        
    return (pd.concat(samples),DINST_HISTOGRAM_LABELS)

def extract_dinstL_features(df):
    samples = []
    DINST_MIN=10e-5
    DINST_MAX=2.5
    DINST_HISTOGRAM_BINS=np.linspace(DINST_MIN, DINST_MAX, num=20)
    DINST_HISTOGRAM_LABELS=["HIST_DINST_%f" % _ for _ in DINST_HISTOGRAM_BINS[:-1]]

    
    if BINNING_TYPE=="freedman_std":  

        da_global,bins_global = freedman_bin_width(df['DinstL_std'], True)

        DINST_MIN=bins_global[0]
        DINST_MAX=bins_global[len(bins_global)-1]
        DINST_HISTOGRAM_BINS=bins_global
        DINST_HISTOGRAM_LABELS = ["HIST_DINST_%f" % _ for _ in DINST_HISTOGRAM_BINS[:-1]]
        for ROI, data in df.groupby('ImageNumber'):
            #print data['Dinst_std']
            dinst_features = generate_dinst_feature_vector(data['DinstL_std'],DINST_MIN,DINST_MAX,DINST_HISTOGRAM_BINS,DINST_HISTOGRAM_LABELS)
            dinst_features['index'] = ROI
            dinst_features = dinst_features.set_index('index')
            samples.append(dinst_features)
    
            
        
        
    return (pd.concat(samples),DINST_HISTOGRAM_LABELS)

##normalisation
def preprocess_object_data(df):

    grouped=df.groupby('ImageNumber')
    zscore = lambda x: (x - x.mean()) / x.std()

    transformed_DC = grouped['Diffusion_Coefficient'].transform(zscore)  
    transformed_MSD = grouped['MSD_0'].transform(zscore)

    DC_std = pd.DataFrame(transformed_DC)
    MSD_std = pd.DataFrame(transformed_MSD)

    DC_std.columns = ['Diffusion_Coefficient_std']
    MSD_std.columns = ['MSD_0_std']
    df=pd.concat([df, DC_std], axis=1,verify_integrity=False)
    df=pd.concat([df, MSD_std], axis=1,verify_integrity=False)
    return df


def preprocess_total_mov_data(df):
    
    grouped=df.groupby('ImageNumber')
    zscore = lambda x: (x - x.mean()) / x.std()
    transformed_Dinst = grouped['total_movement'].transform(zscore)  
    Dinst_std = pd.DataFrame(transformed_Dinst)
    Dinst_std.columns = ['total_movement_std']
    df=pd.concat([df, Dinst_std], axis=1,verify_integrity=False)

    return df

def preprocess_dinst_data(df):

    grouped=df.groupby('ImageNumber')
    zscore = lambda x: (x - x.mean()) / x.std()
    transformed_Dinst = grouped['Dinst'].transform(zscore)  
    Dinst_std = pd.DataFrame(transformed_Dinst)
    Dinst_std.columns = ['Dinst_std']
    df=pd.concat([df, Dinst_std], axis=1,verify_integrity=False)

    return df

def preprocess_dinstL_data(df):

    grouped=df.groupby('ImageNumber')
    zscore = lambda x: (x - x.mean()) / x.std()
    transformed_Dinst = grouped['DinstL'].transform(zscore)  
    Dinst_std = pd.DataFrame(transformed_Dinst)
    Dinst_std.columns = ['DinstL_std']
    df=pd.concat([df, Dinst_std], axis=1,verify_integrity=False)

    return df

def compute_max_bin_values(classification_mode, object_df, point_df):
    max_diff_coeff_global=[]
    max_diff_coeff_len=0
    max_MSD_global=[]
    max_MSD_len=0

    for ROI, data in object_df.groupby('ImageNumber'):
        #Compute Freedman-Diaconis algorithm for MSD_0
        da_global,bins_global = freedman_bin_width(data['Diffusion_Coefficient'], True)
        #print len(bins_global)
        if len(bins_global) > max_diff_coeff_len:
            max_diff_coeff_len=len(bins_global)
            max_diff_coeff_global=[]
            max_diff_coeff_global.append(bins_global)


        #Compute Freedman-Diaconis algorithm for diffusion coefficient
        da_global,bins_global = freedman_bin_width(data['MSD_0'], True)
        #print len(bins_global)
        if len(bins_global) > max_MSD_len:
            max_MSD_len=len(bins_global)
            max_MSD_global=[]

            max_MSD_global.append(bins_global)

    MSD_MIN=max_MSD_global[0][0]
    MSD_MAX=max_MSD_global[0][max_MSD_len-1]
    MSD_HISTOGRAM_BINS=max_MSD_global[0]
    #print MSD_HISTOGRAM_BINS
    MSD_HISTOGRAM_LABELS = ["HIST_MSD_%f" % _ for _ in MSD_HISTOGRAM_BINS[:-1]]

    DENSITY_MIN=max_diff_coeff_global[0][0]
    DENSITY_MAX=max_diff_coeff_global[0][max_diff_coeff_len-1]
    DENSITY_HISTOGRAM_BINS=max_diff_coeff_global[0]
    #print DENSITY_HISTOGRAM_BINS
    DENSITY_HISTOGRAM_LABELS = ["HIST_DENSITY_%f" % _ for _ in DENSITY_HISTOGRAM_BINS[:-1]]
    
    
    if classification_mode=='unsupervised':
        max_dinst_global=[]
        max_dinst_len=0

        for ROI, data in point_df.groupby('ImageNumber'):
            #Compute Freedman-Diaconis algorithm for MSD_0
            da_global,bins_global = freedman_bin_width(data['Dinst'], True)

            if len(bins_global) > max_dinst_len:
                max_dinst_len=len(bins_global)
                max_dinst_global=[]                
                max_dinst_global.append(bins_global)

        DINST_MIN=max_dinst_global[0][0]
        DINST_MAX=max_dinst_global[0][max_dinst_len-1]
        DINST_HISTOGRAM_BINS=max_dinst_global[0]
        DINST_HISTOGRAM_LABELS = ["HIST_DINST_%f" % _ for _ in DINST_HISTOGRAM_BINS[:-1]]
    else:
        #Here we fixed the bin size cause there is no dinst data for labeled datasets
        DINST_MIN=10e-5
        DINST_MAX=2.5
        DINST_HISTOGRAM_BINS=np.linspace(DINST_MIN, DINST_MAX, num=20)
        DINST_HISTOGRAM_LABELS=["HIST_DINST_%f" % _ for _ in DINST_HISTOGRAM_BINS[:-1]]         
    
    return (DENSITY_MIN,DENSITY_MAX,DENSITY_HISTOGRAM_BINS,DENSITY_HISTOGRAM_LABELS,MSD_MIN,MSD_MAX,MSD_HISTOGRAM_BINS,MSD_HISTOGRAM_LABELS,DINST_MIN,DINST_MAX,DINST_HISTOGRAM_BINS,DINST_HISTOGRAM_LABELS)

def extract_features_bin_max(classification_mode, object_df, point_df):
    samples = []
    #features_list=('MSD_0','Diffusion_Coefficient')
    #counter=0
        
    DENSITY_MIN,DENSITY_MAX,DENSITY_HISTOGRAM_BINS,DENSITY_HISTOGRAM_LABELS,MSD_MIN,MSD_MAX,MSD_HISTOGRAM_BINS,MSD_HISTOGRAM_LABELS,DINST_MIN,DINST_MAX,DINST_HISTOGRAM_BINS,DINST_HISTOGRAM_LABELS=compute_max_bin_values(classification_mode, object_df,point_df)
        
    
    for ROI, data in object_df.groupby('ImageNumber'):
        
        # XXX Generate vector of features
        msd_features = generate_msd_feature_vector(data['MSD_0'],MSD_MIN,MSD_MAX,MSD_HISTOGRAM_BINS,MSD_HISTOGRAM_LABELS)      
        diffusion_features = generate_diffusion_coefficient_features_vector(data['Diffusion_Coefficient'],DENSITY_MIN,DENSITY_MAX,DENSITY_HISTOGRAM_BINS,DENSITY_HISTOGRAM_LABELS)
        
        # XXX Merge the set of features
        all_feat = pd.concat([diffusion_features, msd_features], axis=1,verify_integrity=False)
        all_feat['index'] = ROI
        all_feat = all_feat.set_index('index')
        samples.append(all_feat)
    samples = pd.concat(samples)    
        
    sample_dinst=[]    
    for ROI, data in point_df.groupby('ImageNumber'):
        
        dinst_features = generate_dinst_feature_vector(data['Dinst'],DINST_MIN,DINST_MAX,DINST_HISTOGRAM_BINS,DINST_HISTOGRAM_LABELS)
        dinst_features['index'] = ROI
        dinst_features = dinst_features.set_index('index')
        sample_dinst.append(dinst_features)  
                
    sample_dinst=pd.concat(sample_dinst)
    
    
    return (pd.concat([samples, sample_dinst], axis=1,verify_integrity=False),DENSITY_HISTOGRAM_LABELS,MSD_HISTOGRAM_LABELS,DINST_HISTOGRAM_LABELS)


def extract_features_bin_fixed(classification_mode, object_df,point_df):
    samples = []
    #features_list=('MSD_0','Diffusion_Coefficient')
    #counter=0

    DENSITY_MAX = 10e1
    DENSITY_MIN = 10e-5
    DENSITY_HISTOGRAM_BINS = np.logspace(-4, 1, num=20) # BINS to compute the density histogram
    DENSITY_HISTOGRAM_LABELS = ["HIST_DENSITY_%f" % _ for _ in DENSITY_HISTOGRAM_BINS[:-1]]

    MSD_MAX = 0.5
    MSD_MIN = -0.5
    MSD_HISTOGRAM_BINS = np.linspace(MSD_MIN, MSD_MAX, num=20)
    MSD_HISTOGRAM_LABELS = ["HIST_MSD_%f" % _ for _ in MSD_HISTOGRAM_BINS[:-1]]
    
    DINST_MIN=10e-5
    DINST_MAX=2.5
    DINST_HISTOGRAM_BINS=np.linspace(DINST_MIN, DINST_MAX, num=20)
    DINST_HISTOGRAM_LABELS=["HIST_DINST_%f" % _ for _ in DINST_HISTOGRAM_BINS[:-1]] 
    
    for ROI, data in object_df.groupby('ImageNumber'):
        
        # XXX Generate vector of features
        msd_features = generate_msd_feature_vector(data['MSD_0'],MSD_MIN,MSD_MAX,MSD_HISTOGRAM_BINS,MSD_HISTOGRAM_LABELS)      
        diffusion_features = generate_diffusion_coefficient_features_vector(data['Diffusion_Coefficient'],DENSITY_MIN,DENSITY_MAX,DENSITY_HISTOGRAM_BINS,DENSITY_HISTOGRAM_LABELS)

        # XXX Merge the set of features
        all_feat = pd.concat([diffusion_features, msd_features], axis=1,verify_integrity=False)
        all_feat['index'] = ROI
        all_feat = all_feat.set_index('index')
        samples.append(all_feat)
    samples = pd.concat(samples)
    
    
    if classification_mode=='unsupervised':
        sample_dinst=[]    
        for ROI, data in point_df.groupby('ImageNumber'):
            dinst_features = generate_dinst_feature_vector(data['Dinst'],DINST_MIN,DINST_MAX,DINST_HISTOGRAM_BINS,DINST_HISTOGRAM_LABELS)
            dinst_features['index'] = ROI
            dinst_features = dinst_features.set_index('index')
            sample_dinst.append(dinst_features)  

        sample_dinst=pd.concat(sample_dinst)
        return (pd.concat([samples, sample_dinst], axis=1,verify_integrity=False),DENSITY_HISTOGRAM_LABELS,MSD_HISTOGRAM_LABELS,DINST_HISTOGRAM_LABELS)
    else:
        return (samples,DENSITY_HISTOGRAM_LABELS,MSD_HISTOGRAM_LABELS,DINST_HISTOGRAM_LABELS)
        #histFrdDiac, binsFrdDiac = np.histogram(data['MSD_0'], bins=MSD_HISTOGRAM_BINS)
        #histFrdDiac = histFrdDiac /float(histFrdDiac.sum())
        #plt.hist(histFrdDiac, binsFrdDiac)
        #plt.show()

    #fig=plt.figure()
    #fig.savefig('/Users/benjamindartigues/super_class_test/src/histo.pdf',dpi=fig.dpi)
    #plt.close(fig)
    #print "samples after groupby in extract features"
    #print pd.concat(samples)

    #return (pd.concat(samples),DENSITY_HISTOGRAM_LABELS,MSD_HISTOGRAM_LABELS)
def extract_features_bin_std(df):
    """Extract the feature vector of each ROI (ImageNumber? or slot).
    This time we do not have any information on the number of time a particle is visible"""
    samples = []
    #features_list=('MSD_0','Diffusion_Coefficient')
    #counter=0
    
    if BINNING_TYPE=="freedman_max":
        max_diff_coeff_global=[]
        max_diff_coeff_len=0
        max_MSD_global=[]
        max_MSD_len=0


        for ROI, data in df.groupby('ImageNumber'):
            #Compute Freedman-Diaconis algorithm for MSD_0
            print "image number:" + str(ROI)
            da_global,bins_global = freedman_bin_width(data['Diffusion_Coefficient_std'], True)
            print bins_global
            print "nombre de bin for Diffusion_Coefficient_std:" + str(len(bins_global))
            
            if len(bins_global) > max_diff_coeff_len:
                max_diff_coeff_len=len(bins_global)
                max_diff_coeff_global=[]
                max_diff_coeff_global.append(bins_global)
                print "nouvelle taille max pour Diffusion_Coefficient_std:"
                print "###################################################"
                print bins_global
                print "###################################################"


            #Compute Freedman-Diaconis algorithm for diffusion coefficient
            da_global,bins_global = freedman_bin_width(data['MSD_0_std'], True)
            print bins_global
            print "nombre de bin for MSD_0_std:" + str(len(bins_global))
            
            if len(bins_global) > max_MSD_len:
                max_MSD_len=len(bins_global)
                max_MSD_global=[]

                max_MSD_global.append(bins_global)

        MSD_MIN=max_MSD_global[0][0]
        MSD_MAX=max_MSD_global[0][max_MSD_len-1]
        MSD_HISTOGRAM_BINS=max_MSD_global[0]
        #print MSD_HISTOGRAM_BINS
        MSD_HISTOGRAM_LABELS = ["HIST_MSD_%f" % _ for _ in MSD_HISTOGRAM_BINS[:-1]]

        DENSITY_MIN=max_diff_coeff_global[0][0]
        DENSITY_MAX=max_diff_coeff_global[0][max_diff_coeff_len-1]
        DENSITY_HISTOGRAM_BINS=max_diff_coeff_global[0]
        #print DENSITY_HISTOGRAM_BINS
        DENSITY_HISTOGRAM_LABELS = ["HIST_DENSITY_%f" % _ for _ in DENSITY_HISTOGRAM_BINS[:-1]]


    if BINNING_TYPE=="freedman_std": 
        
        da_global,bins_global = freedman_bin_width(df['Diffusion_Coefficient_std'], True)
        DENSITY_MIN=bins_global[0]
        DENSITY_MAX=bins_global[len(bins_global)-1]
        DENSITY_HISTOGRAM_BINS=bins_global
        #print DENSITY_HISTOGRAM_BINS
        DENSITY_HISTOGRAM_LABELS = ["DENSITY_MSD_%f" % _ for _ in DENSITY_HISTOGRAM_BINS[:-1]]
        
        da_global,bins_global = freedman_bin_width(df['MSD_0_std'], True)
        MSD_MIN=bins_global[0]
        MSD_MAX=bins_global[len(bins_global)-1]
        MSD_HISTOGRAM_BINS=bins_global
        #print DENSITY_HISTOGRAM_BINS
        MSD_HISTOGRAM_LABELS = ["HIST_MSD_%f" % _ for _ in MSD_HISTOGRAM_BINS[:-1]]
        
    
    for ROI, data in df.groupby('ImageNumber'):
        
        # XXX Generate vector of features
        
        msd_features = generate_msd_feature_vector(data['MSD_0_std'],MSD_MIN,MSD_MAX,MSD_HISTOGRAM_BINS,MSD_HISTOGRAM_LABELS)      
        diffusion_features = generate_diffusion_coefficient_features_vector(data['Diffusion_Coefficient_std'],DENSITY_MIN,DENSITY_MAX,DENSITY_HISTOGRAM_BINS,DENSITY_HISTOGRAM_LABELS)
        
        # XXX Merge the set of features
        all_feat = pd.concat([diffusion_features, msd_features], axis=1,verify_integrity=False)
        all_feat['index'] = ROI
        all_feat = all_feat.set_index('index')
        samples.append(all_feat)


    return (pd.concat(samples),DENSITY_HISTOGRAM_LABELS,MSD_HISTOGRAM_LABELS)


def extract_features(df,DENSITY_MIN,DENSITY_MAX,DENSITY_HISTOGRAM_BINS,DENSITY_HISTOGRAM_LABELS,MSD_MIN,MSD_MAX,MSD_HISTOGRAM_BINS,MSD_HISTOGRAM_LABELS):
	"""Extract the feature vector of each ROI (ImageNumber? or slot).
	This time we do not have any information on the number of time a particle is visible"""
	samples = []
	features_list=('MSD_0','Diffusion_Coefficient')
        counter=0
        #print df
        #print "samples before groupby in extract features"
        #print df 
	for ROI, data in df.groupby('ImageNumber'):
            # XXX Generate vector of features
            msd_features = generate_msd_feature_vector(data['MSD_0'],MSD_MIN,MSD_MAX,MSD_HISTOGRAM_BINS,MSD_HISTOGRAM_LABELS)
            #da_global,bins_global = freedman_bin_width(data['MSD_0'], True)
            #print 'best bin width for MSD_0 data found with Freedman-Diaconis for image number'+str(ROI)
            #print da_global
            #print 'resulting following number of bins for histogram: '
            #print bins_global
            #print len(bins_global)
            diffusion_features = generate_diffusion_coefficient_features_vector(data['Diffusion_Coefficient'],DENSITY_MIN,DENSITY_MAX,DENSITY_HISTOGRAM_BINS,DENSITY_HISTOGRAM_LABELS)
            #da_global,bins_global = freedman_bin_width(data['Diffusion_Coefficient'], True)
            #print 'best bin width for Diff coeff data found with Freedman-Diaconis for image number'+str(ROI)
            #print da_global
            #print 'resulting following number of bins for histogram: '
            #print bins_global
            #print len(bins_global)
            # XXX Merge the set of features
            all_feat = pd.concat([diffusion_features, msd_features], axis=1,verify_integrity=False)
            all_feat['index'] = ROI
            all_feat = all_feat.set_index('index')
            samples.append(all_feat)


            #histFrdDiac, binsFrdDiac = np.histogram(data['MSD_0'], bins=MSD_HISTOGRAM_BINS)
            #histFrdDiac = histFrdDiac /float(histFrdDiac.sum())
            #plt.hist(histFrdDiac, binsFrdDiac)
            #plt.show()
             
        #fig=plt.figure()
        #fig.savefig('/Users/benjamindartigues/super_class_test/src/histo.pdf',dpi=fig.dpi)
        #plt.close(fig)
        print "samples after groupby in extract features"
        #print pd.concat(samples)
        
	return pd.concat(samples)

def extract_features_of_result(df):
	"""Extract the feature vector of each ROI (ImageNumber? or slot).
	This time we do not have any information on the number of time a particle is visible"""
	samples = []

	for ImageNumber, data in df.groupby('ImageNumber'):
		print "Image Number : "
		print ImageNumber
		print "Data : "
		print data['NbrDinstinTracks']
		nbdata =data['NbrDinstinTracks']
		
		hist, bins = np.histogram(nbdata, bins=bins)
		#hist = hist/float(hist.sum())
		plt.hist(hist, bins=bins, facecolor='m', alpha=0.75)
		plt.xlabel( 'Bins' )
		plt.ylabel( 'NbrDinstinTracks' )
		plt.show()



def associate_pit_to_samples(features, img_df):
	"""Compute the pit of each sample and returns an array of pit"""

	# Builf the Look Up Table from an image to a pit
	pits = img_df['well']
	imgs = img_df['ImageNumber']
        #print pits
        #print imgs

	LUT = dict(zip(imgs, pits))
        #print LUT
	# Get the corresponding pit
	# (XXX as an array and not a DataFrame in order to avoid index issues)
	#

	return features.reset_index()['index'].apply(lambda idx: LUT[idx]).values



# code (OBSOLETE ?)
#if __name__ == '__main__':
#	DATA_DIR = os.path.join(os.path.abspath(os.path.dirname(__file__)), '../../data/cell4.Fig/')
#	DATA_DIR = '/mnt/data/BIC/06062013_14.51_1/Manip_06062013_14.51/'
#	exp_samples = extract_experiment_features(DATA_DIR)

#	exp_samples.boxplot()
#	plt.savefig('boxplot.pdf')



# metadata
__author__ = 'Romain Giot'
__copyright__ = 'Copyright 2013, LaBRI'
__credits__ = ['Romain Giot']
__licence__ = 'GPL'
__version__ = '0.1'
__maintainer__ = 'Romain Giot'
__email__ = 'romain.giot@u-bordeaux1.fr'
__status__ = 'Prototype'


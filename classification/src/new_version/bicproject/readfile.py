#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""Try to read the files generated byt the bic.

XXX Add more explanations.
"""

# imports
import os
import re
import glob
from collections import OrderedDict
import logging
logging.basicConfig(level=logging.INFO)

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from pandas.tools.plotting import scatter_matrix, andrews_curves

from joblib import Memory, Parallel, delayed

from constants import *
#Cache folder
CACHE_DIR = '/mnt/data/results/BIC/cache'
if not os.path.exists(CACHE_DIR):
    logging.error('Cache directory [%s] does not exists!\n Use /tmp insted' % CACHE_DIR)
    CACHE_DIR = '/tmp'


memory = Memory(cachedir=CACHE_DIR, verbose=True)

def extract_slot_features(folder, expname):
    """Extract the features from the files of the folder.
    At the moment, only read the diffusion coefficient and build an histogram.

    TODO Add additional calls to read additional features

    folder:
        Folder which contains the data
    expname:
        Experiment name (used to select which files to read)
    """

    logging.info("Treat exp '" + expname + "' from " + folder)
    assert (folder.find(expname.replace("_MIA",".MIA")) != -1)



    coeff_fname = os.path.join(folder, expname + "-AllROI-D.txt")
    coeff_feat = extract_diffusion_coefficient_features(coeff_fname)

    msd_fname = coeff_fname
    msd_feat = extract_msd_features(msd_fname)


    traj_fname = os.path.join(folder, expname + ".trc")
    traj_feat = extract_trajectory_features(traj_fname)

    # merge features
    all_feat = pd.concat([coeff_feat, traj_feat, msd_feat], axis=1)
    all_feat.index = [folder]

    return all_feat



@memory.cache
def extract_trajectory_features(traj_fname):
    """Read the trajectory file and extract its histogram
    
    traj_fname: 
        File containing the trajectories

    Returns the trajectory features (i.e. histogram)
    """

    assert (os.path.exists(traj_fname))

    data = pd.io.parsers.read_csv(traj_fname,
                                names = ['TRAJ_ID', 'FRAME_NB', 'X', 'Y', 'MOLECULE_SIZE', 'INTENSITY'],
                                sep=None,
                                skipinitialspace=True,
                                index_col=False)

    # Get the number of frames per trajectory
    nb_frames = np.array(
        [group.count().values[0] for _id, group in data[['TRAJ_ID', 'FRAME_NB']].groupby('TRAJ_ID')]
    )

    # Cut extremums
    nb_frames[nb_frames<TRAJECTORY_FRAMES_MIN] = TRAJECTORY_FRAMES_MIN
    nb_frames[nb_frames>TRAJECTORY_FRAMES_MAX] = TRAJECTORY_FRAMES_MAX

    # Compute a normalized histogram
    hist, bins = np.histogram(nb_frames, bins=TRAJECTORY_FRAMES_HISTOGRAM_BINS)
    hist = hist / float(hist.sum())

    # Build the features
    feat = OrderedDict( zip(TRAJECTORY_FRAMES_HISTOGRAM_LABELS, hist))
    #df = pd.DataFrame([feat], index=[traj_fname])
    df = pd.DataFrame([feat])
    df = df.reindex_axis(feat.keys(), axis=1) #order seems eroneous

    return df


def extract_msd_features(msd_fname):
    """Read Mean Square Distance features.

    msd_name: 
        file which contains the MSD (in fact the same than the diffusion coefficient)
    """

    assert(os.path.exists(msd_fname))

    # configuration of pandas to read the file properly
    data = pd.io.parsers.read_csv(
                msd_fname,
                sep="\t",
                skipinitialspace=True,
                header=None,
                names = [ROI_COL, TRACE_COL, DENSITY_COL, MSD_COL, MSE_COL],
                skiprows=3,
                index_col=False,
                encoding='latin1')
                

    # Verify that the file read respect the structure of the files used during the development
    # of the library
    assert len(data[ROI_COL].unique()) == 1, "Currently implemented if there is one ROI"
    assert (data[TRACE_COL].unique().shape[0] == data[TRACE_COL].count()) , "Only one density per Trace"

    # Get the density values and fix the extremums
    msd = data[MSD_COL].values

    return generate_MSD_feature_vector(msd)



def plotHistogram(data):

    histFrdDiac, binsFrdDiac = np.histogram(data, bins='fd')
    print histFrdDiac
    print binsFrdDiac
    histFrdDiac = histFrdDiac/float(histFrdDiac.sum())
    plt.hist(histFrdDiac, binsFrdDiac, normed=1, facecolor='g', alpha=0.75)

    plt.show()



def plotHistogram2(df):
    plt.figure(1)
    temp = 211
    for ROI, data in df.groupby('ImageNumber'):
        plt.subplot(temp)
        histFrdDiac, binsFrdDiac = np.histogram(data['MSD_0'], bins='fd')
        histFrdDiac = histFrdDiac/float(histFrdDiac.sum())
        plt.hist(histFrdDiac, binsFrdDiac, normed=True, facecolor='m', alpha=0.75)
        plt.xlabel( 'Bins' )
        plt.ylabel( 'MSD sum' )
        plt.show()
        temp=temp+1


def generate_MSD_feature_vector(msd):
    """Generate the MSD feature vector from the MSD data"""

    msd[msd<MSD_MIN] = MSD_MIN
    msd[msd>MSD_MAX] = MSD_MAX
    # print "MSD : "
    # print msd
    #print("MSD_MIN : ", MSD_MIN, "; MSD_MAX : ",MSD_MAX)
    #print("????? : ",  msd[msd>MSD_MAX])

    # Compute a normalized histogram
    hist, bins = np.histogram(msd, 
                       bins=MSD_HISTOGRAM_BINS)
    hist = hist/float(hist.sum())
    #MSD_HISTOGRAM_LABELS =bins
    #plt.hist(hist, bins=bins, facecolor='m', alpha=0.75)

    # Build the features
    feat = OrderedDict( zip(MSD_HISTOGRAM_LABELS, hist))
    df = pd.DataFrame([feat])
    #df = pd.DataFrame([feat], index=[coeff_fname])
    df = df.reindex_axis(feat.keys(), axis=1) #order seems eroneous

    return df

def generate_MSE_feature_vector(mse):
    """Generate the MSD feature vector from the MSD data"""

    # print "MSD : "
    # print msd
    mse[mse<MSD_MIN] = MSD_MIN
    mse[mse>MSD_MAX] = MSD_MAX

    #print("MSD_MIN : ", MSD_MIN, "; MSD_MAX : ",MSD_MAX)
    #print("????? : ",  msd[msd>MSD_MAX])

    # Compute a normalized histogram
    hist, bins = np.histogram(mse, 
                       bins=MSD_HISTOGRAM_BINS)
    hist = hist/float(hist.sum())

    # Build the features
    feat = OrderedDict( zip(MSD_HISTOGRAM_LABELS, hist))
    df = pd.DataFrame([feat])
    #df = pd.DataFrame([feat], index=[coeff_fname])
    df = df.reindex_axis(feat.keys(), axis=1) #order seems eroneous

    return df



@memory.cache
def extract_diffusion_coefficient_features(coeff_fname):
    """Read the diffusion coefficient and build the appropriate histogram.

    coeff_name:
        File containing the coefficient of each path
    """

    assert(os.path.exists(coeff_fname))

    # configuration of pandas to read the file properly
    data = pd.io.parsers.read_csv(
                coeff_fname,
                sep="\t",
                skipinitialspace=True,
                header=None,
                names = [ROI_COL, TRACE_COL, DENSITY_COL, MSD_COL, MSE_COL],
                skiprows=3,
                index_col=False,
                encoding='latin1')
                

 
    # Verify that the file read respect the structure of the files used during the development
    # of the library
    assert len(data[ROI_COL].unique()) == 1, "Currently implemented if there is one ROI"
    assert (data[TRACE_COL].unique().shape[0] == data[TRACE_COL].count()) , "Only one density per Trace"

    
    # Get the density values and fix the extremums
    density = data[DENSITY_COL].values
    return generate_diffusion_coefficient_features_vector(density)

def generate_diffusion_coefficient_features_vector(density):
    density[density<DENSITY_MIN] = DENSITY_MIN
    density[density>DENSITY_MAX] = DENSITY_MAX

    # Compute a normalized histogram
    hist, bins = np.histogram(density, 
                       bins=DENSITY_HISTOGRAM_BINS)
    hist = hist/float(hist.sum())

    # Build the features
    feat = OrderedDict( zip(DENSITY_HISTOGRAM_LABELS, hist))
    df = pd.DataFrame([feat])
    #df = pd.DataFrame([feat], index=[coeff_fname])
    df = df.reindex_axis(feat.keys(), axis=1) #order seems eroneous

    return df



def _extract_experiment_features_inner_loop(expdir):
        logging.info("Treat the folder " + expdir)
        expname = os.path.basename(expdir).replace('.MIA', '_MIA')
        expdir = os.path.join(expdir, 'tracking')
        assert os.path.exists(expdir)

        return extract_slot_features(expdir, expname)


def extract_experiment_features(experiment_dir):
    """Extract the features of each slot of the experiment.
    The method has been developped with a data folder containing several MIA folders.
    It seems it is not the case with the new datasets.
    """

    logging.info("Get feature samples for experiment in " + experiment_dir)

    # BUG never parallel here ...
    samples = Parallel(n_jobs=1, verbose=10)(
        delayed(_extract_experiment_features_inner_loop)(expdir)
            for expdir in glob.glob(os.path.join(experiment_dir, '*.MIA'))
    )

    return pd.concat(samples)



# code (OBSOLETE ?)
if __name__ == '__main__':
    DATA_DIR = os.path.join(os.path.abspath(os.path.dirname(__file__)), '../../data/cell4.Fig/')
    DATA_DIR = '/mnt/data/BIC/06062013_14.51_1/Manip_06062013_14.51/'
    exp_samples = extract_experiment_features(DATA_DIR)

    exp_samples.boxplot()
    plt.savefig('boxplot.pdf')



# metadata
__author__ = 'Romain Giot'
__copyright__ = 'Copyright 2013, LaBRI'
__credits__ = ['Romain Giot']
__licence__ = 'GPL'
__version__ = '0.1'
__maintainer__ = 'Romain Giot'
__email__ = 'romain.giot@u-bordeaux1.fr'
__status__ = 'Prototype'

